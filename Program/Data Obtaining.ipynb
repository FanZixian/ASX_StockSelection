{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data from yahoo finance package\n",
    "import yfinance as yf\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists\n"
     ]
    }
   ],
   "source": [
    "path = \"E:/NUS_Exchange/Research/Datasets/\"\n",
    "try:\n",
    "    os.mkdir(path + \"Output\")\n",
    "    os.mkdir(path + \"Data\")\n",
    "    os.mkdir(path + \"Output/GridSearchCV_Result\")\n",
    "    os.mkdir(path + \"Output/HoldOutValidation\")\n",
    "except:\n",
    "    print(\"Folder already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readX(pathname):\n",
    "    '''\n",
    "    Read X related file\n",
    "    '''\n",
    "    df = pd.read_csv(pathname, index_col=[0], header=[0])\n",
    "    return df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some functions calculations are inspired by the website:\n",
    "https://blog.quantinsti.com/build-technical-indicators-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMA calculation\n",
    "def EWMA(data): \n",
    "    EMA = pd.Series(data['Close'].ewm(span = 15, min_periods = 15 - 1).mean(), \n",
    "                 name = '15_Days_EWMA') \n",
    "    data = data.join(EMA) \n",
    "    return data\n",
    "\n",
    "# Returns RSI values\n",
    "def RSI(close, periods = 15):\n",
    "    \n",
    "    close_delta = close.diff()\n",
    "\n",
    "    # Make two series: one for lower closes and one for higher closes\n",
    "    up = close_delta.clip(lower=0)\n",
    "    down = -1 * close_delta.clip(upper=0)\n",
    "    \n",
    "    ma_up = up.ewm(com = periods - 1, adjust=True, min_periods = periods).mean()\n",
    "    ma_down = down.ewm(com = periods - 1, adjust=True, min_periods = periods).mean()\n",
    "\n",
    "    rsi = ma_up / ma_down\n",
    "    rsi = 100 - (100/(1 + rsi))\n",
    "    return rsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MFI index definition\n",
    "def gain(x):\n",
    "    return ((x > 0) * x).sum()\n",
    "\n",
    "def loss(x):\n",
    "    return ((x < 0) * x).sum()\n",
    "\n",
    "# Calculate money flow index\n",
    "def MFI(high, low, close, volume, n=15):\n",
    "    typical_price = (high + low + close)/3\n",
    "    money_flow = typical_price * volume\n",
    "    mf_sign = np.where(typical_price > typical_price.shift(1), 1, -1)\n",
    "    signed_mf = money_flow * mf_sign\n",
    "    mf_avg_gain = signed_mf.rolling(n).apply(gain, raw=True)\n",
    "    mf_avg_loss = signed_mf.rolling(n).apply(loss, raw=True)\n",
    "    return (100 - (100 / (1 + (mf_avg_gain / abs(mf_avg_loss))))).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATR index function\n",
    "def ATR(high, low, close, n=15):\n",
    "    tr = np.amax(np.vstack(((high - low).to_numpy(), (abs(high - close)).to_numpy(), (abs(low - close)).to_numpy())).T, axis=1)\n",
    "    return pd.Series(tr).rolling(n).mean().to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ForceIndex function\n",
    "def ForceIndex(data, ndays = 10): \n",
    "    FI = pd.Series(data['Close'].diff(ndays) * data['Volume'], name = 'ForceIndex') \n",
    "    data = data.join(FI) \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACD\n",
    "def MACD(data, slowspan = 26, quickspan = 12):\n",
    "    slow = data['Close'].transform(lambda x: x.ewm(span=slowspan, adjust=False).mean())\n",
    "    quick = data['Close'].transform(lambda x: x.ewm(span=quickspan, adjust=False).mean())\n",
    "    return slow - quick"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Price Data indicator generating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:/NUS_Exchange/Research/Datasets/Data/Price\\\\XDI_AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\XEC_AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\XJR_AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\XLD_AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\XNT_AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\XNV_AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\XVI_AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AFLI.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AORD.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^ATLI.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^ATOI.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AXAF.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AXAT.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AXBW.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AXDJ.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AXEJ.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AXFJ.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AXGD.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AXHJ.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AXIJ.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AXJO.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AXKO.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AXMD.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AXMJ.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AXMM.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AXNJ.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AXPJ.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AXRE.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AXSJ.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AXSO.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AXTJ.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AXUJ.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price\\\\^AXXJ.csv']\n"
     ]
    }
   ],
   "source": [
    "# Recursively put .csv files into list\n",
    "import os\n",
    " \n",
    "def list_dir(file_dir):\n",
    "    # list_csv = []\n",
    "    dir_list = os.listdir(file_dir)\n",
    "    for cur_file in dir_list:\n",
    "        path = os.path.join(file_dir,cur_file)\n",
    "        if os.path.isfile(path):\n",
    "            # print(\"{0} : is file!\".format(cur_file))\n",
    "            dir_files = os.path.join(file_dir, cur_file)\n",
    "        if os.path.splitext(path)[1] == '.csv':\n",
    "            csv_file = os.path.join(file_dir, cur_file)\n",
    "            # print(os.path.join(file_dir, cur_file))\n",
    "            # print(csv_file)\n",
    "            list_csv.append(csv_file)\n",
    "        if os.path.isdir(path):\n",
    "            # print(\"{0} : is dir\".format(cur_file))\n",
    "            # print(os.path.join(file_dir, cur_file))\n",
    "            list_dir(path)\n",
    "    return list_csv\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    paths = r'E:/NUS_Exchange/Research/Datasets/Data/Price'\n",
    "    list_csv = []\n",
    "    list_dir(file_dir=paths)\n",
    "    print(list_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trials\n",
    "# companiesName.iloc[0][0]\n",
    "# x = yf.Ticker(\"1AL.F\")\n",
    "# x_historical = x.history(start=\"2020-01-01\", end=\"2022-12-31\")\n",
    "# x_historical.to_csv(path+\"/Data/StockPriceAndDividend/ConsDisFundamentalData/\" + \"1AL.F\" + \".csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we assume 30 days to be a window to train the datasets, then we will create the relavant indicators from price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot do positional indexing on DatetimeIndex with these indexers [2017-01-01 00:00:00] of type Timestamp",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m     x_df\u001b[39m.\u001b[39mto_csv(path\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/Data/Price_Index/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m filename[\u001b[39m45\u001b[39m:] \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m list_csv:\n\u001b[1;32m---> 36\u001b[0m     pricedataobtain(i)\n",
      "Cell \u001b[1;32mIn[10], line 32\u001b[0m, in \u001b[0;36mpricedataobtain\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m     30\u001b[0m x_df \u001b[39m=\u001b[39m x_df\u001b[39m.\u001b[39mset_index([\u001b[39m'\u001b[39m\u001b[39mDate\u001b[39m\u001b[39m'\u001b[39m], drop\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     31\u001b[0m split_date \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mTimestamp(\u001b[39m'\u001b[39m\u001b[39m2017-01-01\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m x_df \u001b[39m=\u001b[39m x_df\u001b[39m.\u001b[39;49miloc[split_date:]\n\u001b[0;32m     33\u001b[0m x_df\u001b[39m.\u001b[39mto_csv(path\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/Data/Price_Index/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m filename[\u001b[39m45\u001b[39m:] \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\asus\\anaconda3\\envs\\pt-gpu\\lib\\site-packages\\pandas\\core\\indexing.py:1073\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1070\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m   1072\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m-> 1073\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32mc:\\Users\\asus\\anaconda3\\envs\\pt-gpu\\lib\\site-packages\\pandas\\core\\indexing.py:1602\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1596\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\n\u001b[0;32m   1597\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mDataFrame indexer is not allowed for .iloc\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1598\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConsider using .loc for automatic alignment.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1599\u001b[0m     )\n\u001b[0;32m   1601\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mslice\u001b[39m):\n\u001b[1;32m-> 1602\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_slice_axis(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   1604\u001b[0m \u001b[39mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   1605\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(key)\n",
      "File \u001b[1;32mc:\\Users\\asus\\anaconda3\\envs\\pt-gpu\\lib\\site-packages\\pandas\\core\\indexing.py:1637\u001b[0m, in \u001b[0;36m_iLocIndexer._get_slice_axis\u001b[1;34m(self, slice_obj, axis)\u001b[0m\n\u001b[0;32m   1634\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   1636\u001b[0m labels \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39m_get_axis(axis)\n\u001b[1;32m-> 1637\u001b[0m labels\u001b[39m.\u001b[39;49m_validate_positional_slice(slice_obj)\n\u001b[0;32m   1638\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_slice(slice_obj, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\asus\\anaconda3\\envs\\pt-gpu\\lib\\site-packages\\pandas\\core\\indexes\\base.py:4212\u001b[0m, in \u001b[0;36mIndex._validate_positional_slice\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4206\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[0;32m   4207\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_validate_positional_slice\u001b[39m(\u001b[39mself\u001b[39m, key: \u001b[39mslice\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   4208\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   4209\u001b[0m \u001b[39m    For positional indexing, a slice must have either int or None\u001b[39;00m\n\u001b[0;32m   4210\u001b[0m \u001b[39m    for each of start, stop, and step.\u001b[39;00m\n\u001b[0;32m   4211\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4212\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_indexer(\u001b[39m\"\u001b[39;49m\u001b[39mpositional\u001b[39;49m\u001b[39m\"\u001b[39;49m, key\u001b[39m.\u001b[39;49mstart, \u001b[39m\"\u001b[39;49m\u001b[39miloc\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   4213\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_indexer(\u001b[39m\"\u001b[39m\u001b[39mpositional\u001b[39m\u001b[39m\"\u001b[39m, key\u001b[39m.\u001b[39mstop, \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   4214\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_indexer(\u001b[39m\"\u001b[39m\u001b[39mpositional\u001b[39m\u001b[39m\"\u001b[39m, key\u001b[39m.\u001b[39mstep, \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\asus\\anaconda3\\envs\\pt-gpu\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6634\u001b[0m, in \u001b[0;36mIndex._validate_indexer\u001b[1;34m(self, form, key, kind)\u001b[0m\n\u001b[0;32m   6631\u001b[0m \u001b[39massert\u001b[39;00m kind \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mgetitem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   6633\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_integer(key):\n\u001b[1;32m-> 6634\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invalid_indexer(form, key)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot do positional indexing on DatetimeIndex with these indexers [2017-01-01 00:00:00] of type Timestamp"
     ]
    }
   ],
   "source": [
    "def pricedataobtain(filename):\n",
    "    x_historical = readX(filename)\n",
    "    x_df = x_historical.copy()\n",
    "    # All of them are yesterday data\n",
    "    x_df[\"OpenClose_spread\"] = x_df.apply(lambda x: x[\"Close\"] - x[\"Open\"], axis=1).shift(1).fillna(0)\n",
    "    x_df[\"Highlow_spread\"] = x_df.apply(lambda x: x[\"High\"] - x[\"Low\"], axis=1).shift(1).fillna(0)\n",
    "    # All of them are Moving average data using close price\n",
    "    # Stock price data\n",
    "    x_df[\"5_Days_MA\"] = x_df[[\"Close\"]].rolling(window=5).mean()\n",
    "    x_df[\"10_Days_MA\"] = x_df[[\"Close\"]].rolling(window=10).mean()\n",
    "    x_df[\"15_Days_MA\"] = x_df[[\"Close\"]].rolling(window=15).mean()\n",
    "    x_df[\"30_Days_MA\"] = x_df[[\"Close\"]].rolling(window=30).mean()\n",
    "    x_df[\"5_Days_VAR\"] = x_df[[\"Close\"]].rolling(window=5).var()\n",
    "    x_df[\"15_Days_VAR\"] = x_df[[\"Close\"]].rolling(window=15).var()\n",
    "    x_df[\"30_Days_VAR\"] = x_df[[\"Close\"]].rolling(window=30).var()\n",
    "\n",
    "    # Technical indicators\n",
    "    EWMA(x_df)\n",
    "\n",
    "\n",
    "    # Macro economic indicators\n",
    "\n",
    "    # Drop meaningless features\n",
    "    x_df = x_df.drop(columns=[\"Open\", \"High\", \"Low\", \"Volume\", \"Adj_Close\"], axis=1)\n",
    "    x_df = x_df[16:]\n",
    "    x_df = x_df.rename(columns={\"Close\" : \"Price\"})\n",
    "\n",
    "    # Transform the index to date time\n",
    "    x_df['Date'] = pd.to_datetime(x_df.index)\n",
    "    x_df = x_df.set_index(['Date'], drop=True)\n",
    "\n",
    "    x_df.to_csv(path+\"/Data/Price_Index/\" + filename[45:] + \".csv\")\n",
    "\n",
    "for i in list_csv:\n",
    "    pricedataobtain(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fundamental Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:/NUS_Exchange/Research/Datasets/Data/Fundamental\\\\ConsDisFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental\\\\ConsStapFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental\\\\EnergyFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental\\\\FinanceFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental\\\\HealthcareFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental\\\\IndustrialFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental\\\\ITFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental\\\\LargeCapFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental\\\\MaterialFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental\\\\MediumCapFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental\\\\SmallCapFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental\\\\TeleFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental\\\\UtilitiesFundamentalData.csv']\n"
     ]
    }
   ],
   "source": [
    "def list_dir(file_dir):\n",
    "    # list_csv = []\n",
    "    dir_list = os.listdir(file_dir)\n",
    "    for cur_file in dir_list:\n",
    "        path = os.path.join(file_dir,cur_file)\n",
    "        if os.path.isfile(path):\n",
    "            # print(\"{0} : is file!\".format(cur_file))\n",
    "            dir_files = os.path.join(file_dir, cur_file)\n",
    "        if os.path.splitext(path)[1] == '.csv':\n",
    "            csv_file = os.path.join(file_dir, cur_file)\n",
    "            # print(os.path.join(file_dir, cur_file))\n",
    "            # print(csv_file)\n",
    "            list_csv.append(csv_file)\n",
    "        if os.path.isdir(path):\n",
    "            # print(\"{0} : is dir\".format(cur_file))\n",
    "            # print(os.path.join(file_dir, cur_file))\n",
    "            list_dir(path)\n",
    "    return list_csv\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    paths = r'E:/NUS_Exchange/Research/Datasets/Data/Fundamental'\n",
    "    list_csv = []\n",
    "    list_dir(file_dir=paths)\n",
    "    print(list_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the fundamental data\n",
    "'''\n",
    "ConsDisFundamentalData_df = readX(path+\"/Fundamental/ConsDisFundamentalData.csv\")\n",
    "ConsStapFundamentalData_df = readX(path+\"/Fundamental/ConsStapFundamentalData.csv\")\n",
    "EnergyFundamentalData_df = readX(path+\"/Fundamental/EnergyFundamentalData.csv\")\n",
    "FinanceFundamentalData_df = readX(path+\"/Fundamental/FinanceFundamentalData.csv\")\n",
    "HealthcareFundamentalData_df = readX(path+\"/Fundamental/HealthcareFundamentalData.csv\")\n",
    "IndustrialFundamentalData_df = readX(path+\"/Fundamental/IndustrialFundamentalData.csv\")\n",
    "ITFundamentalData_df = readX(path+\"/Fundamental/ITFundamentalData.csv\")\n",
    "MaterialFundamentalData_df = readX(path+\"/Fundamental/MaterialFundamentalData.csv\")\n",
    "MediumCapFundamentalData_df = readX(path+\"/Fundamental/MediumCapFundamentalData.csv\")\n",
    "SmallCapFundamentalData_df = readX(path+\"/Fundamental/SmallCapFundamentalData.csv\")\n",
    "TeleFundamentalData_df = readX(path+\"/Fundamental/MediumCapFundamentalData.csv\")\n",
    "UtilitiesFundamentalData_df = readX(path+\"/Fundamental/SmallCapFundamentalData.csv\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deal with nan data\n",
    "# Also, store the name of the stocks into one csv files\n",
    "Name = pd.DataFrame()\n",
    "for i in list_csv:\n",
    "    x_df = readX(i)\n",
    "    x_df = x_df.dropna(how=\"any\")\n",
    "    x_df.to_csv(path+\"/Data/Fundamental_Stock/\" + i[50:])\n",
    "    Name.append(pd.DataFrame(x_df.index))\n",
    "Name = Name.drop_duplicates()\n",
    "Name.index=pd.Series(range(0,2089))\n",
    "Name.to_csv(path+\"/Data/Fundamental_Stock/Name.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:/NUS_Exchange/Research/Datasets/Data/Fundamental_Stock\\\\ConsDisFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental_Stock\\\\ConsStapFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental_Stock\\\\EnergyFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental_Stock\\\\FinanceFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental_Stock\\\\HealthcareFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental_Stock\\\\IndustrialFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental_Stock\\\\ITFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental_Stock\\\\LargeCapFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental_Stock\\\\MaterialFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental_Stock\\\\MediumCapFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental_Stock\\\\SmallCapFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental_Stock\\\\TeleFundamentalData.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Fundamental_Stock\\\\UtilitiesFundamentalData.csv']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    paths = r'E:/NUS_Exchange/Research/Datasets/Data/Fundamental_Stock'\n",
    "    list_csv = []\n",
    "    list_dir(file_dir=paths)\n",
    "    print(list_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also, store the name of the stocks into one csv files\n",
    "Name = pd.DataFrame()\n",
    "for i in list_csv:\n",
    "    x_df = readX(i)\n",
    "    Name = Name.append(pd.DataFrame(x_df.index))\n",
    "Name = Name.drop_duplicates()\n",
    "Name.index=pd.Series(range(0,900))\n",
    "Name.to_csv(path+\"/Data/Fundamental_Stock/Name.csv\")\n",
    "\n",
    "# After the data cleaning, only 900 stocks are stored in the name file"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Download stock prices included in the S&P/ASX 50 from yahoo finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trials\n",
    "# companiesName.iloc[0][0]\n",
    "\n",
    "stockcode = \"XRO.AX\"\n",
    "\n",
    "x = yf.Ticker(stockcode)\n",
    "x_historical = x.history(start=\"2015-01-01\", end=\"2022-12-31\")\n",
    "x_historical.to_csv(path+\"/Data/Price_Stock/\" + stockcode + \".csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have ignored some stocks, such as TLC, WTC, EDV, COL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\AIA.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\ALL.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\AMC.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\ANZ.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\APA.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\ASX.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\BHP.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\BXB.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\CBA.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\COH.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\CPU.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\CSL.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\FMG.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\FPH.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\GMG.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\IAG.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\IGO.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\JHX.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\MIN.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\MQG.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\NAB.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\NCM.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\NST.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\ORG.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\PLS.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\QAN.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\QBE.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\REA.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\REH.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\RHC.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\RIO.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\RMD.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\S32.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\SCG.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\SHL.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\SOL.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\STO.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\SUN.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\TLS.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\TWE.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\WBC.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\WDS.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\WES.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\WOW.AX.csv', 'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock\\\\XRO.AX.csv']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    paths = r'E:/NUS_Exchange/Research/Datasets/Data/Price_Stock'\n",
    "    list_csv = []\n",
    "    list_dir(file_dir=paths)\n",
    "    print(list_csv)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we assume 30 days to be a window to train the datasets, then we will create the relavant indicators from price data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pricedataobtain(filename):\n",
    "    x_historical = readX(filename)\n",
    "    x_df = x_historical.copy()\n",
    "    # All of them are yesterday data\n",
    "\n",
    "    # Technical fundamental indicators:\n",
    "    x_df[\"OpenClose_spread\"] = x_df.apply(lambda x: x[\"Close\"] - x[\"Open\"], axis=1).shift(1).fillna(0)\n",
    "    x_df[\"Highlow_spread\"] = x_df.apply(lambda x: x[\"High\"] - x[\"Low\"], axis=1).shift(1).fillna(0)\n",
    "    # All of them are Moving average data using close price\n",
    "    x_df[\"5_Days_MA\"] = x_df[[\"Close\"]].rolling(window=5).mean()\n",
    "    x_df[\"10_Days_MA\"] = x_df[[\"Close\"]].rolling(window=10).mean()\n",
    "    x_df[\"15_Days_MA\"] = x_df[[\"Close\"]].rolling(window=15).mean()\n",
    "    x_df[\"30_Days_MA\"] = x_df[[\"Close\"]].rolling(window=30).mean()\n",
    "    x_df[\"5_Days_VAR\"] = x_df[[\"Close\"]].rolling(window=5).var()\n",
    "    x_df[\"15_Days_VAR\"] = x_df[[\"Close\"]].rolling(window=15).var()\n",
    "    x_df[\"30_Days_VAR\"] = x_df[[\"Close\"]].rolling(window=30).var()\n",
    "    \n",
    "    # Technical advanced indicators:\n",
    "    x_df = EWMA(x_df)\n",
    "    x_df[\"15_Days_RSI\"] = RSI(x_df['Close'])\n",
    "    x_df[\"15_Days_MFI\"] = MFI(x_df[\"High\"], x_df[\"Low\"], x_df[\"Close\"], x_df[\"Volume\"])\n",
    "    x_df[\"15_Days_ATR\"] = ATR(x_df[\"High\"], x_df[\"Low\"], x_df[\"Close\"])    \n",
    "    x_df = ForceIndex(x_df)\n",
    "    x_df[\"Typical_MACD\"] = MACD(x_df)\n",
    "\n",
    "\n",
    "    # Dropout meaningless features\n",
    "    x_df = x_df.drop(columns=[\"Open\", \"High\", \"Low\"], axis=1)\n",
    "    x_df = x_df[31:]\n",
    "    x_df = x_df.rename(columns={\"Close\" : \"Price\"})\n",
    "\n",
    "    # Transform the index to date time\n",
    "    x_df['Date'] = pd.to_datetime(x_df.index)\n",
    "    x_df['Date'] = x_df['Date'].apply(lambda x: x.replace(tzinfo=None))\n",
    "    x_df = x_df.set_index(['Date'], drop=True)\n",
    "\n",
    "    x_df.to_csv(path+\"/Data/ASX_stockconsidering/\" + filename[51:] + \".csv\")\n",
    "\n",
    "for i in list_csv:\n",
    "    pricedataobtain(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3cd2506ed87cf616db555091a1f51ea367a230f8881c6d5beb7cb815d220d913"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
